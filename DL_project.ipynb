{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_project_(1)_(1)_(2) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78109762e74b45c8aa5ffc3b5f44f1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a594db4ff9ef43b6a1936c12d2f5f42e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0cfdcf9fe63a4aad89759a0a6b035f13",
              "IPY_MODEL_62566a3b957840d0a41c6e1fb039c5c2"
            ]
          }
        },
        "a594db4ff9ef43b6a1936c12d2f5f42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cfdcf9fe63a4aad89759a0a6b035f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e48917cdc808406a931e15ffb87af589",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 608,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 608,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb7246d81fbe4f3f982d050e3c6cf196"
          }
        },
        "62566a3b957840d0a41c6e1fb039c5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_678d0493f1984d4d8683f5546f99afc6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 608/608 [00:00&lt;00:00, 1.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51345b19885c4fa1918058f794c000d0"
          }
        },
        "e48917cdc808406a931e15ffb87af589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb7246d81fbe4f3f982d050e3c6cf196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "678d0493f1984d4d8683f5546f99afc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51345b19885c4fa1918058f794c000d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b560832a2d84499aec9f073ba565f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f6f3ccb613346a5b6a19f61a1c2f348",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4188f90570bc4cae9321e04303bbee08",
              "IPY_MODEL_51f86cfb90c140e783aeb34dfec07cc2"
            ]
          }
        },
        "9f6f3ccb613346a5b6a19f61a1c2f348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4188f90570bc4cae9321e04303bbee08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c1e6af5140d40c9931bbddadb1eacb5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1713123,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1713123,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75c324a40bcd4cd79425a612e2568705"
          }
        },
        "51f86cfb90c140e783aeb34dfec07cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f937d2b508dc4e17b8db2d63d5f7edf5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.71M/1.71M [00:00&lt;00:00, 11.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cb511532e3248e9b3afcc26207f2361"
          }
        },
        "2c1e6af5140d40c9931bbddadb1eacb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75c324a40bcd4cd79425a612e2568705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f937d2b508dc4e17b8db2d63d5f7edf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cb511532e3248e9b3afcc26207f2361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afe85bb2f00c42689c3f1537b85f8dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fbcea44471a457e9440f9b7e445f8d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f0ea98ffc3c492db1fe54cd25a5b1a6",
              "IPY_MODEL_4298563791274f2da828e8a941021ed9"
            ]
          }
        },
        "9fbcea44471a457e9440f9b7e445f8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0ea98ffc3c492db1fe54cd25a5b1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50c5e094537b4307aff4ddc84a6f6abe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1270925,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1270925,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cd32ae284b347f9a20a3e87f563c51f"
          }
        },
        "4298563791274f2da828e8a941021ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_feb1fb3a1d6f4e9b9c64ec02787b4a6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.27M/1.27M [00:00&lt;00:00, 6.95MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45032d4b973149388fb74b0bd73a9a0a"
          }
        },
        "50c5e094537b4307aff4ddc84a6f6abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cd32ae284b347f9a20a3e87f563c51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feb1fb3a1d6f4e9b9c64ec02787b4a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45032d4b973149388fb74b0bd73a9a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3a2552e803e4f7293579462b924c616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcbc19b4b1ea4258a3b8f5e338b30efc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ecbc73c953944d2991e46ce8bfe3e0a",
              "IPY_MODEL_788aa4f39c2845ea8cda52257abdf4c7"
            ]
          }
        },
        "bcbc19b4b1ea4258a3b8f5e338b30efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ecbc73c953944d2991e46ce8bfe3e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_621a7fb21d334e94ba5bfb3198dc3639",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 551290714,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 551290714,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa92074601d04545a4de75d929f06692"
          }
        },
        "788aa4f39c2845ea8cda52257abdf4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_573950112a7c47f6a83c16900abe4fd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 551M/551M [00:11&lt;00:00, 46.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a9bb50576924d29971b999f98246877"
          }
        },
        "621a7fb21d334e94ba5bfb3198dc3639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa92074601d04545a4de75d929f06692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "573950112a7c47f6a83c16900abe4fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a9bb50576924d29971b999f98246877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2exOOW7Fd7qr"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "G9-e7TY86osG"
      },
      "source": [
        "!pip install transformers rouge-score nltk sklearn seaborn pandas torch torchvision pytelegrambotapi "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiZkSE6w6x8f"
      },
      "source": [
        "import json\n",
        "import math\n",
        "import re\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import telebot\n",
        "import random\n",
        "\n",
        "from telebot import apihelper\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu as bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from random import shuffle\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7iRof9kJ10W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "78109762e74b45c8aa5ffc3b5f44f1ab",
            "a594db4ff9ef43b6a1936c12d2f5f42e",
            "0cfdcf9fe63a4aad89759a0a6b035f13",
            "62566a3b957840d0a41c6e1fb039c5c2",
            "e48917cdc808406a931e15ffb87af589",
            "eb7246d81fbe4f3f982d050e3c6cf196",
            "678d0493f1984d4d8683f5546f99afc6",
            "51345b19885c4fa1918058f794c000d0",
            "0b560832a2d84499aec9f073ba565f03",
            "9f6f3ccb613346a5b6a19f61a1c2f348",
            "4188f90570bc4cae9321e04303bbee08",
            "51f86cfb90c140e783aeb34dfec07cc2",
            "2c1e6af5140d40c9931bbddadb1eacb5",
            "75c324a40bcd4cd79425a612e2568705",
            "f937d2b508dc4e17b8db2d63d5f7edf5",
            "1cb511532e3248e9b3afcc26207f2361",
            "afe85bb2f00c42689c3f1537b85f8dae",
            "9fbcea44471a457e9440f9b7e445f8d0",
            "6f0ea98ffc3c492db1fe54cd25a5b1a6",
            "4298563791274f2da828e8a941021ed9",
            "50c5e094537b4307aff4ddc84a6f6abe",
            "2cd32ae284b347f9a20a3e87f563c51f",
            "feb1fb3a1d6f4e9b9c64ec02787b4a6a",
            "45032d4b973149388fb74b0bd73a9a0a",
            "b3a2552e803e4f7293579462b924c616",
            "bcbc19b4b1ea4258a3b8f5e338b30efc",
            "6ecbc73c953944d2991e46ce8bfe3e0a",
            "788aa4f39c2845ea8cda52257abdf4c7",
            "621a7fb21d334e94ba5bfb3198dc3639",
            "fa92074601d04545a4de75d929f06692",
            "573950112a7c47f6a83c16900abe4fd6",
            "7a9bb50576924d29971b999f98246877"
          ]
        },
        "outputId": "4d9a0433-00fd-48c4-e469-f6f6dcc9d53a"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78109762e74b45c8aa5ffc3b5f44f1ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=608.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b560832a2d84499aec9f073ba565f03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1713123.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe85bb2f00c42689c3f1537b85f8dae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1270925.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:890: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3a2552e803e4f7293579462b924c616",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=551290714.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhtEvRuhPBkA"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ytJw1H8cTB",
        "outputId": "c9f89a76-697e-4073-dafe-b3eb5b3620e7"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer.get_vocab()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50258, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sELv2TJnB6_b"
      },
      "source": [
        "BOS, EOS, PAD, SP1, SP2, HISTORY, INPUT, REPLY = '<bos>', '<eos>', '<pad>', '<speaker1>', '<speaker2>', '<history>', '<input>', '<reply>'\n",
        "ATTR_TO_SPECIAL_TOKEN = {\n",
        "    'bos_token': BOS, \n",
        "    'eos_token': EOS, \n",
        "    'pad_token': PAD,\n",
        "    'additional_special_tokens': [SP1, SP2, HISTORY, INPUT, REPLY]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3XjpYtqmIco"
      },
      "source": [
        "orig_num_tokens = model.get_input_embeddings().num_embeddings\n",
        "num_added_tokens = tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "if num_added_tokens > 0:\n",
        "    model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-IEE_MowDI9",
        "outputId": "4272989e-1585-4e3a-9f3c-247ebdb2982b"
      },
      "source": [
        "model.load_state_dict(torch.load('flibusta_model'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lftGOXAO3rgU"
      },
      "source": [
        "with open('tokenized_flibusta_small', 'rb') as f:\n",
        "    tokenized_data = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gizcefMm2BoH"
      },
      "source": [
        "def normalize(lines):\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        new_line = []\n",
        "        for item in line:\n",
        "            item = item.lower()\n",
        "            item = re.sub('[,.!?();:\\_\\\\/\\[\\]]', '', item)\n",
        "            new_line.append(item)\n",
        "        data.append(new_line)\n",
        "    return data\n",
        "\n",
        "def tokenize(lines):\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        data.append([tokenizer.encode_plus(item)['input_ids'] for item in line])\n",
        "    return data\n",
        "\n",
        "def delete_bad_sized_strings(lines):\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        new_line = []\n",
        "        for item in line:\n",
        "            if len(item) < 3 or len(item) > 15:\n",
        "                if len(new_line) > 1:\n",
        "                    data.append(new_line)\n",
        "                new_line = []\n",
        "                continue\n",
        "            new_line.append(item)\n",
        "        if len(new_line) > 1:\n",
        "           data.append(new_line)\n",
        "    return data\n",
        "\n",
        "def build_data(lines, history_len=3):\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        if len(line) < 2:\n",
        "            continue\n",
        "        history = []\n",
        "        for i in range(len(line)-1):\n",
        "            input = line[i]\n",
        "            reply = line[i+1]\n",
        "            item = {\n",
        "                'history': history.copy(),\n",
        "                'input': input,\n",
        "                'reply': reply\n",
        "            }\n",
        "            data.append(item)\n",
        "            if len(history) == history_len:\n",
        "                history = history[1:]\n",
        "            history.append(input)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smj0Z2N4KFM"
      },
      "source": [
        "def process_data(data, history_len=3):\n",
        "    data = normalize(data)\n",
        "    data = tokenize(data)\n",
        "    data = delete_bad_sized_strings(data)\n",
        "    return build_data(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX4FJHqie4cN"
      },
      "source": [
        "def preprocess_data_for_model(src, dest):\n",
        "    with open(src, 'rb') as f:\n",
        "        lines = pickle.load(f)\n",
        "    no_doubled_lines = []\n",
        "    seen = set()\n",
        "    for line in lines:\n",
        "        start = line[0]\n",
        "        if start in seen:\n",
        "            continue\n",
        "        seen.add(start)\n",
        "        no_doubled_lines.append(lines)\n",
        "    tokenized_data = process_data(no_doubled_lines)\n",
        "    cleared_data = []\n",
        "    take = True\n",
        "    for item in tokenized_data:\n",
        "        if item['input'] == item['reply']:\n",
        "            take = False\n",
        "            continue\n",
        "        if len(item['history']) == 0:\n",
        "            take = True\n",
        "        if not take:\n",
        "            continue\n",
        "        cleared_data.append(item)\n",
        "    tokenized_data = cleared_data\n",
        "    with open(dest, 'wb') as f:\n",
        "        pickle.dump(tokenized_data, f)\n",
        "    return tokenized_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJrAsB7LfPiP"
      },
      "source": [
        "tokenized_data = preprocess_data_for_model('test', 'tokenized_flibusta_small')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37eA3oO-eMSr"
      },
      "source": [
        "# Dataset и Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpJUX3gqKE50"
      },
      "source": [
        "batch_size = 64\n",
        "batches = []\n",
        "\n",
        "for i_batch in range(math.ceil(len(tokenized_data) / batch_size)):\n",
        "    batches.append(tokenized_data[i_batch*batch_size:(i_batch+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XenTfNXXmN6u"
      },
      "source": [
        "class SequenceBucketingData(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bos = BOS\n",
        "        self.eos = EOS\n",
        "        self.pad = 0\n",
        "        self.sp1 = SP1\n",
        "        self.sp2 = SP2\n",
        "        self.bos_emb = tokenizer.convert_tokens_to_ids(self.bos)\n",
        "        self.eos_emb = tokenizer.convert_tokens_to_ids(self.eos)\n",
        "        self.sp1_emb = tokenizer.convert_tokens_to_ids(self.sp1)\n",
        "        self.sp2_emb = tokenizer.convert_tokens_to_ids(self.sp2)\n",
        "        self.history = tokenizer.convert_tokens_to_ids(HISTORY)\n",
        "        self.input = tokenizer.convert_tokens_to_ids(INPUT)\n",
        "        self.reply = tokenizer.convert_tokens_to_ids(REPLY)\n",
        "        \n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def padding(self, text, length):\n",
        "        text += [self.pad] * (length - len(text))\n",
        "        return text\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch = self.data[index]\n",
        "        \n",
        "        xx = []\n",
        "        yy = []\n",
        "        pi = []\n",
        "        am = []\n",
        "        tti = []\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            item = batch[i]\n",
        "            history = item['history']\n",
        "            input = item['input']\n",
        "            reply = item['reply']\n",
        "\n",
        "            position_ids = []\n",
        "            token_type_ids = []\n",
        "\n",
        "            batch_item = []\n",
        "            \n",
        "            curr_speaker = self.sp1_emb\n",
        "            for item in history:\n",
        "                for i in range(len(item)+1):\n",
        "                    position_ids.append(i+1)\n",
        "                    token_type_ids.append(curr_speaker)\n",
        "                item = [self.history] + item\n",
        "                batch_item.append(item)\n",
        "                if curr_speaker == self.sp1_emb:\n",
        "                    curr_speaker = self.sp2_emb\n",
        "                else:\n",
        "                    curr_speaker = self.sp1_emb\n",
        "            batch_item.append([self.input] + input)\n",
        "            for i in range(len(input)+1):\n",
        "                position_ids.append(i+1)\n",
        "                token_type_ids.append(self.sp1_emb)\n",
        "            batch_item.append([self.reply] + reply)\n",
        "            for i in range(len(reply)+1): \n",
        "                position_ids.append(i+1)\n",
        "                token_type_ids.append(self.sp2_emb)\n",
        "            \n",
        "            batch_item_flat = reduce(lambda x,y: x+y, batch_item)\n",
        "\n",
        "            x = batch_item_flat\n",
        "            y = batch_item_flat[1:] + [self.eos_emb]\n",
        "\n",
        "            attn_mask = [el != 0 for el in x]\n",
        "\n",
        "            xx.append(x)\n",
        "            yy.append(y)\n",
        "            pi.append(position_ids)          \n",
        "            am.append(attn_mask)\n",
        "            tti.append(token_type_ids)\n",
        "        \n",
        "        max_length = max([len(item) for item in xx])\n",
        "        for i in range(len(xx)):\n",
        "            xx[i] = self.padding(xx[i], max_length)\n",
        "            yy[i] = self.padding(yy[i], max_length)\n",
        "            pi[i] = self.padding(pi[i], max_length)\n",
        "            am[i] = self.padding(am[i], max_length)\n",
        "            tti[i] = self.padding(tti[i], max_length)\n",
        "        \n",
        "        xx = torch.tensor(xx).to(device)\n",
        "        yy = torch.tensor(yy).to(device)\n",
        "        pi = torch.tensor(pi).to(device)\n",
        "        am = torch.tensor(am).to(device)\n",
        "        tti = torch.tensor(tti).to(device)\n",
        "        return xx, yy, pi, am, tti"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvxlXIf3DglS"
      },
      "source": [
        "validation_start_index = int(len(batches) * 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3vlxgAUMN6G"
      },
      "source": [
        "train_dataset_seq = SequenceBucketingData(batches[:-validation_start_index],\n",
        "                                          tokenizer\n",
        "                                        )\n",
        "valid_dataset_seq = SequenceBucketingData(batches[-validation_start_index:],\n",
        "                                          tokenizer\n",
        "                                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6MjjbRvMedv"
      },
      "source": [
        "train_loader = DataLoader(train_dataset_seq, batch_size=1, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset_seq, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB7rlPP0eTQa"
      },
      "source": [
        "# Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsQ4Jym6E2vQ"
      },
      "source": [
        "def ids_to_string(ids, tokenizer):\n",
        "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(ids,skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlulJmEKHW--"
      },
      "source": [
        "def get_nlp_metrics(preds, yy, tokenizer):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    rouge_f1 = []\n",
        "    bleus = []\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'])\n",
        "    for i in range(len(preds)):\n",
        "        pred = preds[i]\n",
        "        y = yy[i]\n",
        "        pred = ids_to_string(pred, tokenizer)\n",
        "        y = ids_to_string(y, tokenizer)\n",
        "        scores = scorer.score(pred, y)\n",
        "        rouge_f1.append(scores['rougeL'].fmeasure)\n",
        "        bleus.append(bleu([pred], y, smoothing_function=smoothie))\n",
        "    return rouge_f1, bleus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02CO48FdSiYZ"
      },
      "source": [
        "def train(lm_model, opt, cri, x, y, pi, am, tti, batch_size, curr_step, accumulation_step, clip_norm, tok):\n",
        "    lm_model.train()\n",
        "    output = lm_model.forward(input_ids=x, attention_mask=am, token_type_ids=tti)\n",
        "    lm_pred = output.logits\n",
        "    loss = cri(lm_pred.view(-1, lm_pred.size(-1)), y.view(-1))\n",
        "    loss.backward()\n",
        "    \n",
        "    lm_pred = F.softmax(lm_pred, dim=2)\n",
        "    lm_pred = torch.argmax(lm_pred, dim=-1)\n",
        "    rouge_f1, bleus = get_nlp_metrics(lm_pred[0], y[0], tok)\n",
        "    rouge_f1_score = np.mean(rouge_f1)\n",
        "    bleu_score = np.mean(bleus)\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
        "    if batch_size < 16:\n",
        "        if curr_step % accumulation_step == 0:\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "    else:\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "         \n",
        "    return loss, rouge_f1_score, bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHqxFYJ0N7PZ"
      },
      "source": [
        "def validate(lm_model, cri, x, y, pi, am, tti, tok):\n",
        "    lm_model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = lm_model.forward(input_ids=x, attention_mask=am, token_type_ids=tti)\n",
        "        \n",
        "    lm_pred = output.logits     \n",
        "    loss = cri(lm_pred.view(-1, lm_pred.size(-1)), y.view(-1))\n",
        "\n",
        "    lm_pred = F.softmax(lm_pred, dim=2)\n",
        "    lm_pred = torch.argmax(lm_pred, dim=-1)\n",
        "\n",
        "    rouge_f1, bleus = get_nlp_metrics(lm_pred[0], y[0], tok)\n",
        "    rouge_f1_score = np.mean(rouge_f1)\n",
        "    bleu_score = np.mean(bleus)\n",
        "    return loss, rouge_f1_score, bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2xDjuIOMmWg"
      },
      "source": [
        "def iterate(lm_model, t_loader, v_loader, epochs, opt, cri, accumulation_step, clip_norm, tok, last_n_perpl=500):\n",
        "    perpl = []\n",
        "    rouges = []\n",
        "    bleus = []\n",
        "    \n",
        "    prev_val_perplexity = 100000000\n",
        "    bad_iters = 0\n",
        "    for n_epoch in range(epochs):\n",
        "        if bad_iters > 3:\n",
        "            return lm_model, perpl, rouges, bleus\n",
        "        progress_bar = tqdm(total=len(t_loader), desc=f'Epoch {n_epoch + 1} of {epochs}')\n",
        "        curr_step = 1\n",
        "        for x, y, pi, am, tti in t_loader:\n",
        "            if bad_iters > 3:\n",
        "                return lm_model, perpl, rouges, bleus\n",
        "            if curr_step % 2000 == 0:\n",
        "                epoch_val_perpl = []\n",
        "                epoch_val_rouge = []\n",
        "                epoch_val_bleu = []\n",
        "\n",
        "                for x, y, pi, am, tti in v_loader:\n",
        "                    batch_size = len(x)\n",
        "                    loss, rouge_f1_score, bleu_score = validate(lm_model, cri, x, y, pi, am, tti, tok)\n",
        "                    perplexity = np.exp(loss.item())\n",
        "                    epoch_val_perpl.append(perplexity)\n",
        "                    epoch_val_rouge.append(rouge_f1_score)\n",
        "                    epoch_val_bleu.append(bleu_score)\n",
        "\n",
        "                curr_perpl = np.mean(epoch_val_perpl)\n",
        "                curr_rouge = np.mean(epoch_val_rouge)\n",
        "                curr_bleu = np.mean(epoch_val_bleu)\n",
        "                print(\"\\nCurr val perpl: \", curr_perpl)\n",
        "                \n",
        "                if curr_perpl < prev_val_perplexity:\n",
        "                    bad_iters = 0\n",
        "                    torch.save(lm_model.state_dict(), f'dicts/model')\n",
        "                    torch.save(opt.state_dict(), f'dicts/optimizer')\n",
        "                    prev_val_perplexity = curr_perpl\n",
        "                else:\n",
        "                    bad_iters += 1\n",
        "                    \n",
        "            batch_size = len(x)\n",
        "            loss, rouge_f1_score, bleu_score = train(lm_model, opt, cri, x, y, pi, am, tti, batch_size, curr_step, accumulation_step, clip_norm, tok)\n",
        "            rouges.append(rouge_f1_score)\n",
        "            bleus.append(bleu_score)\n",
        "            perplexity = np.exp(loss.item())\n",
        "            perpl.append(perplexity)\n",
        "            curr_step += 1\n",
        "            progress_bar.set_postfix(perplexity=np.mean(perpl[-last_n_perpl:]))\n",
        "            progress_bar.update()\n",
        "        progress_bar.close()\n",
        "\n",
        "        for x, y, pi, am, tti in v_loader:\n",
        "            batch_size = len(x)\n",
        "            loss, rouge_f1_score, bleu_score = validate(lm_model, cri, x, y, pi, am, tti, tok)\n",
        "            perplexity = np.exp(loss.item())\n",
        "            epoch_val_perpl.append(perplexity)\n",
        "            epoch_val_rouge.append(rouge_f1_score)\n",
        "            epoch_val_bleu.append(bleu_score)\n",
        "\n",
        "        curr_perpl = np.mean(epoch_val_perpl)\n",
        "        curr_rouge = np.mean(epoch_val_rouge)\n",
        "        curr_bleu = np.mean(epoch_val_bleu)\n",
        "        print(\"\\nCurr val perpl: \", curr_perpl)\n",
        "\n",
        "        if curr_perpl < prev_val_perplexity:\n",
        "            bad_iters = 0\n",
        "            torch.save(lm_model.state_dict(), f'dicts/model')\n",
        "            torch.save(opt.state_dict(), f'dicts/optimizer')\n",
        "            prev_val_perplexity = curr_perpl\n",
        "        else:\n",
        "            bad_iters += 1\n",
        "        \n",
        "    return lm_model, perpl, rouges, bleus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fKOGggpRkm2"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "optim = AdamW(params=model.parameters(), lr=5e-5, correct_bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvtAXlGpOclB"
      },
      "source": [
        "lm_model, perpls, rouges, bleus = iterate(model, train_loader, valid_loader, 3, optim, criterion, 1, 3, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jWOzKtEPQb6"
      },
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KQpL7ByedYy"
      },
      "source": [
        "# Генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EmT7GYf6XmT"
      },
      "source": [
        "def top_filtering(logits, top_k=0., top_p=0.9, threshold=-float('Inf'), filter_value=-float('Inf')):\n",
        "    \"\"\" Filter a distribution of logits using top-k, top-p (nucleus) and/or threshold filtering\n",
        "        Args:\n",
        "            logits: logits distribution shape (vocabulary size)\n",
        "            top_k: <=0: no filtering, >0: keep only top k tokens with highest probability.\n",
        "            top_p: <=0.0: no filtering, >0.0: keep only a subset S of candidates, where S is the smallest subset\n",
        "                whose total probability mass is greater than or equal to the threshold top_p.\n",
        "                In practice, we select the highest probability tokens whose cumulative probability mass exceeds\n",
        "                the threshold top_p.\n",
        "            threshold: a minimal threshold to keep logits\n",
        "    \"\"\"\n",
        "    assert logits.dim() == 1  # Only work for batch size 1 for now - could update but it would obfuscate a bit the code\n",
        "    top_k = min(top_k, logits.size(-1))\n",
        "    if top_k > 0:\n",
        "        # Remove all tokens with a probability less than the last token in the top-k tokens\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        # Compute cumulative probabilities of sorted tokens\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probabilities = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold\n",
        "        sorted_indices_to_remove = cumulative_probabilities > top_p\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        # Back to unsorted indices and set them to -infinity\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "\n",
        "    indices_to_remove = logits < threshold\n",
        "    logits[indices_to_remove] = filter_value\n",
        "\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saE5qN5qjR5p"
      },
      "source": [
        "def generate(model, input, attention_mask, tti, next_speaker, max_len=50):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(max_len):\n",
        "            input_batch = input.unsqueeze(0).unsqueeze(0)\n",
        "            am_batch = torch.tensor(attention_mask).to(device).unsqueeze(0).unsqueeze(0)\n",
        "            tti_batch = torch.tensor(tti).to(device).unsqueeze(0).unsqueeze(0)\n",
        "            output = model.forward(input_ids=input, \n",
        "                                   attention_mask=am_batch,\n",
        "                                   token_type_ids=tti_batch\n",
        "                                   )\n",
        "            lm_pred = output.logits\n",
        "            logits = lm_pred[len(lm_pred)-1, :]\n",
        "            k = 10\n",
        "            p = 0.9\n",
        "            filtered_logits = top_filtering(logits, top_p=p, top_k=k)\n",
        "            pred = F.softmax(filtered_logits, dim=0)\n",
        "            new_token = torch.multinomial(pred, 1)\n",
        "            \n",
        "            input = torch.cat((input, new_token.view(1)))\n",
        "            generated.append(new_token)\n",
        "            if new_token == tokenizer.convert_tokens_to_ids(EOS):\n",
        "                break\n",
        "            attention_mask.append(1)\n",
        "            tti.append(next_speaker)\n",
        "    return generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9kwy1HGuJja"
      },
      "source": [
        "replics = [\n",
        "    {\"tag\":HISTORY, \"text\": 'совсем разложились надо же бульдозерами давить'},\n",
        "    {\"tag\":HISTORY, \"text\": 'или срок годности переклеить'},\n",
        "    {\"tag\":INPUT, \"text\": 'а потом бульдозером раздавить и по федеральным каналам показать'},\n",
        "    {\"tag\":REPLY, \"text\": ''},\n",
        "]\n",
        "sp1 = tokenizer.convert_tokens_to_ids(SP1)\n",
        "sp2 = tokenizer.convert_tokens_to_ids(SP2)\n",
        "curr_sp_1 = True\n",
        "inp = []\n",
        "am = []\n",
        "tti = []\n",
        "for replic in replics:\n",
        "    replic = [tokenizer.convert_tokens_to_ids(replic[\"tag\"])] + tokenizer.encode_plus(replic['text'])['input_ids']\n",
        "    if curr_sp_1:\n",
        "        use = sp1\n",
        "    else:\n",
        "        use = sp2\n",
        "    am += [1] * len(replic)\n",
        "    tti += [use] * len(replic)\n",
        "    inp += replic\n",
        "    curr_sp_1 = !curr_sp_1\n",
        "next_speaker = sp1 if curr_sp_1 else sp2\n",
        "generated = generate(model, torch.tensor(inp).to(device), am, tti, next_speaker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-vZkCVEnVJE"
      },
      "source": [
        "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(generated, skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGuAqlMjgqOk"
      },
      "source": [
        "# Бот"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGNXL3BJ5MzX"
      },
      "source": [
        "secret = \"\" # вставить код"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51izQG95h61c"
      },
      "source": [
        "bot = telebot.TeleBot(secret)\n",
        "\n",
        "history = {}\n",
        "\n",
        "def generate_reply(input, user_history):\n",
        "    seed = random.choice(seeds)\n",
        "    replics = [{\"tag\":HISTORY, \"text\": sentence} for sentence in user_history]\n",
        "    replics.append({\"tag\":INPUT, \"text\": input})\n",
        "    replics.append({\"tag\":REPLY, \"text\": ''})\n",
        "\n",
        "    sp1 = tokenizer.convert_tokens_to_ids(SP1)\n",
        "    sp2 = tokenizer.convert_tokens_to_ids(SP2)\n",
        "    curr_sp_1 = True\n",
        "    inp = []\n",
        "    am = []\n",
        "    tti = []\n",
        "    for replic in replics:\n",
        "        replic = [tokenizer.convert_tokens_to_ids(replic[\"tag\"])] + tokenizer.encode_plus(replic['text'])['input_ids']\n",
        "        if curr_sp_1:\n",
        "            use = sp1\n",
        "        else:\n",
        "            use = sp2\n",
        "        am += [1] * len(replic)\n",
        "        tti += [use] * len(replic)\n",
        "        inp += replic\n",
        "        curr_sp_1 = !curr_sp_1\n",
        "    next_speaker = sp1 if curr_sp_1 else sp2\n",
        "    generated = generate(model, torch.tensor(inp).to(device), am, tti, next_speaker)\n",
        "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(generated, skip_special_tokens=True)) \n",
        "\n",
        "@bot.message_handler(commands=['history'])\n",
        "def handle_history(message):\n",
        "    curr_user = message.from_user.id\n",
        "    user_history = history.get(curr_user)\n",
        "    if user_history is None or len(user_history) == 0:\n",
        "        bot.send_message(message.chat.id, 'Истории нет')\n",
        "        return\n",
        "    msgs = ['{0}. {1}'.format(i, user_history[i]) for i in range(len(user_history))]\n",
        "    bot.send_message(message.chat.id, '\\n'.join(msgs))\n",
        "    \n",
        "@bot.message_handler(commands=['ping'])\n",
        "def handle_ping(message):\n",
        "    bot.send_message(message.chat.id, 'pong')\n",
        "\n",
        "@bot.message_handler(commands=['restart'])\n",
        "def handle_start(message):\n",
        "    curr_user = message.from_user.id\n",
        "    history[curr_user] = []\n",
        "    bot.send_message(message.chat.id, 'История была сброшена')\n",
        "\n",
        "def update_history(old_history, input, reply):\n",
        "    new_history = old_history.copy()\n",
        "    new_history.append(input)\n",
        "    new_history.append(reply)\n",
        "    if len(new_history) > 3:\n",
        "        return new_history[-3:]\n",
        "    return new_history\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def send_text(message):\n",
        "    curr_user = message.from_user.id\n",
        "    user_history = history.get(curr_user)\n",
        "    if user_history is None:\n",
        "        history[curr_user] = []\n",
        "        user_history = history.get(curr_user)\n",
        "    user_input = normalize([[message.text]])[0][0]\n",
        "    reply = generate_reply(user_input, user_history)\n",
        "\n",
        "    new_history = update_history(user_history, user_input, reply)\n",
        "    history[curr_user] = new_history\n",
        "    bot.send_message(message.chat.id, reply)\n",
        "\n",
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KKIe_RbjHFu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}