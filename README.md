# Finetune RU GPT - Chit chat aka болталка
## Краткий обзор задачи
Проводился файнтьюнинг RU GPT на диалогах, взятых из книг. Хотелось добавить модели понимание не только того, что есть вопрос и ответ, но и контекста диалога.

## Бейзлайн
В качестве бейзлайна на вход модели подавались вектора из вопроса и ответа. Обучение проводилось без attention_mask и token_type_ids.
Такая модель неплохо могла предсказывать следующие токены, но у нее не было понимания истории разговора, а также ей требовался сид для генерации ответа.

## Результаты
Получилась зафайнтьюнить модель на диалогах с историей не больше трех, а также сделать телеграм бота для ведения с ним диалога.
Основной метрикой была перплексия, так как она лучше всего согласуется с отзывами реальных людей, пробующих использовать бота.
BLEU и ROUGE тоже измерялись, но для диалоговых моделей и значения крайне малы. 
В итоге на валидационной выборке перплексия была около 61.  
По итогу можно сказать, что количество данных очень важно для файнтьюнинга RU GPT; 
так, при обучении на ~800 000 примеров переобучение начинается с 5-6 эпохи, при ~80 000 - уже со 2 эпохи.  
Также важно удалять дубли:
- удалять диалоги с одинаковыми первыми фразам нужно для того, чтоб модель не переучивалась на определенных вопросах;
- удалять диалоги с совпадающими ответами и вопросами надо для того, чтобы модель не начинала часто отвечать на вопрос им же самим.

## Воспроизведение результатов
### В случае, если хочется просто потыкать в модель:
Модель - https://drive.google.com/file/d/1NVNem2SUXWTaH20oSKUa9n9su54dHkFY/view?usp=sharing  
Оптимайзер - https://drive.google.com/file/d/1D1NuUPgHECU4VXH8NbkGkvG4WkypbsnB/view?usp=sharing

### В случае, если хочется обучить модель:
Или:
- взять данные из tokenized_flibusta_small

Или:
- вызвать функцию `preprocess_data_for_model(src, dest)`:
  - src - файл с данными (данные должны быть в виде массива массивов диалогов: `[["реплика 1," "реплика 2"], ["реплика 1," "реплика 2", "реплика 3"]]`
  , записанных в файл в бинарном виде с помощью `pickle.dump`)
  - dest - файл, куда запишутся подготовленные данные
  - функция также возвращает подготовленные данные
  - результат будет в виде массива словарей со следующими ключами:
    - history - история разговора; значение - массив массивов индексов токенов
    - input - вопрос; массив индексов токенов
    - reply - ответ; массив индексов токенов
    
   - пример результата:  `[{"input": [1,2,3], "reply": [1,4,5,6], "history": [[4,10,2,7], [8,4]]}]`