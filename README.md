# Finetune RU GPT - Chit chat aka болталка
## Краткий обзор задачи
Проводился файнтьюнинг RU GPT на диалогах, взятых из книг. Хотелось добавить модели понимание не только того, что есть вопрос и ответ, но и контекста диалога.

## Бейзлайн
В качестве бейзлайна на вход модели подавались вектора из вопроса и ответа. Обучение проводилось без attention_mask и token_type_ids.
Такая модель неплохо могла предсказывать следующие токены, но у нее не было понимания истории разговора, а также ей требовался сид для генерации ответа.

## Результаты
Получилась зафайнтьюнить модель на диалогах с историей не больше трех, а также сделать телеграм бота для ведения с ним диалога.
Основной метрикой была перплексия, так как она лучше всего согласуется с отзывами реальных людей, пробующих использовать бота.
BLEU и ROUGE тоже измерялись, но для диалоговых моделей и значения крайне малы. 
В итоге на валидационной выборке перплексия была около 61.  
По итогу можно сказать, что количество данных очень важно для файнтьюнинга RU GPT; 
так, при обучении на ~800 000 примеров переобучение начинается с 5-6 эпохи, при ~80 000 - уже со 2 эпохи.  
Также важно удалять дубли:
- удалять диалоги с одинаковыми первыми фразам нужно для того, чтоб модель не переучивалась на определенных вопросах;
- удалять диалоги с совпадающими ответами и вопросами надо для того, чтобы модель не начинала часто отвечать на вопрос им же самим.

## Воспроизведение результатов
### В случае, если хочется просто потыкать в модель:
Модель - https://drive.google.com/file/d/1NVNem2SUXWTaH20oSKUa9n9su54dHkFY/view?usp=sharing  
Оптимайзер - https://drive.google.com/file/d/1D1NuUPgHECU4VXH8NbkGkvG4WkypbsnB/view?usp=sharing

### В случае, если хочется обучить модель:
Или:
- взять данные из tokenized_flibusta_small

Или:
- взять данные отсюда https://drive.google.com/file/d/1Efe7QAstdg4zK5Ch4zfqw0OV7TPF12tV/view?usp=sharing
- обрезать их (использовался первый 1 000 000 строк)
- положить в файл в бинарном виде с помощью pickle.dump(data)
- забрать данные из него в ноутбуке
- удалить дублирующиеся данные (те диалоги, что начинаются с одной и той же фразы) - применить ячейку, начинающуюся с `no_doubled_lines = []`
- сунуть данные в process_data
- почистить данные от таких диалогов, в которых ответ на вопрос совпадает с самим вопросом - применить ячейку, начинающуюся с `cleared_data = []`
- сохранить данные для дальнейшго использования